{
  "metadata": {
    "name": "BizAndTipsDataProcessing",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "First, we process business data"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val bizJSONPath \u003d \"bdad_proj/yelp_academic_dataset_business.json\"\nval bizDataPath \u003d \"bdad_proj/business_data\""
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val businessDF \u003d spark.read.json(bizJSONPath)\nbusinessDF.cache"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "businessDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val bizCountDF \u003d businessDF.groupBy($\"state\").count.sort($\"count\")\nbizCountDF.show(50)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "businessDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval changedBizDF \u003d businessDF.withColumn(\"stars\", businessDF(\"stars\").cast(\"double\"))\n      .withColumn(\"review_count\", businessDF(\"review_count\").cast(\"long\"))\n      .withColumn(\"is_open\", businessDF(\"is_open\").cast(\"boolean\"))\n      .withColumn(\"latitude\", businessDF(\"latitude\").cast(\"double\"))\n      .withColumn(\"longitude\", businessDF(\"longitude\").cast(\"double\"))\n      .withColumn(\"categories\", split(trim(businessDF(\"categories\")), \",\"))\n      .na.drop(\"any\")\n      .filter($\"address\" \u003d!\u003d \"\" \u0026\u0026 $\"business_id\" \u003d!\u003d \"\" \u0026\u0026 $\"city\" \u003d!\u003d \"\" \u0026\u0026 $\"name\" \u003d!\u003d \"\" \u0026\u0026 length($\"state\") \u003d\u003d\u003d 2 \u0026\u0026 length($\"postal_code\") \u003d\u003d\u003d 5) //filter out non-american postal code and empty strings\n      .toDF"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "changedBizDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "changedBizDF.write.mode(\"overwrite\").parquet(bizDataPath)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Now we process tips data"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tipDF \u003d spark.read.json(\"bdad_proj/yelp_academic_dataset_tip.json\")\ntipDF.cache.show"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tipDF.printSchema\nval tipTrainDF \u003d tipDF.withColumn(\"date\", to_timestamp(tipDF(\"date\"), \"yyyy-MM-dd HH:mm:ss\"))\n      .withColumn(\"compliment_count\", tipDF(\"compliment_count\").cast(\"long\"))\n      .withColumn(\"cleanse_text\", regexp_replace($\"text\", \"[\\\\W\u0026\u0026[^\\\\s+]]\", \"\"))\n      .withColumn(\"words\", split($\"cleanse_text\", \" \"))\ntipTrainDF.show\ntipTrainDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tipDF.select($\"text\").show(false)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tipTrainDF.write.mode(\"overwrite\").parquet(\"bdad_proj/tip_data\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Train word2vec data"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tipTrainDF \u003d spark.read.parquet(\"bdad_proj/tip_data\")"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.{Word2Vec, Word2VecModel}\nval w2v \u003d new Word2Vec().setInputCol(\"words\").setOutputCol(\"features\").setVectorSize(100).setMinCount(0)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val model \u003d w2v.fit(tipTrainDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Load model from HDFS"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.{Word2Vec, Word2VecModel}\nval model \u003d Word2VecModel.load(\"bdad_proj/tip_word2vec_model\")"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "model.getVectors.show"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "model.findSynonyms(\"car\", 5).show(false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Persistence model"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "model.write.overwrite.save(\"bdad_proj/tip_word2vec_model\")"
    }
  ]
}