{
  "metadata": {
    "name": "CheckInDataProcessing",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Read checkin data"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val checkinDF \u003d spark.read.json(\"bdad_proj/yelp_academic_dataset_checkin.json\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "checkinDF.show\ncheckinDF.printSchema"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Data cleansing"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val checkinCleanDF \u003d checkinDF\n    .na.drop(\"any\")\n    .filter($\"business_id\" \u003d!\u003d \"\" \u0026\u0026 length($\"date\") \u003d!\u003d 19)\n    .withColumn(\"date\", explode(split($\"date\", \",\")))\n    .withColumn(\"ts\", to_timestamp($\"date\", \"yyyy-MM-dd HH:mm:ss\"))\n    .drop($\"date\")\ncheckinCleanDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "checkinCleanDF.write.mode(\"overwrite\").parquet(\"bdad_proj/checkin_data\")"
    }
  ]
}