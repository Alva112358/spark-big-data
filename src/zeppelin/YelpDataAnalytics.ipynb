{
  "metadata": {
    "name": "YelpDataAnalytics",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Read Data"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \nBusiness Data"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val bizDF \u003d spark.read.parquet(\"bdad_proj/business_data\")\nbizDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "bizDF.createOrReplaceTempView(\"biz_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Explode categories"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// All Categories\nbizDF.where($\"is_open\" \u003d\u003d\u003d true).select($\"business_id\", explode($\"categories\").as(\"category\")).createOrReplaceTempView(\"biz_cat_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Tip Data"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tipDF \u003d spark.read.parquet(\"bdad_proj/tip_data\")\ntipDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "tipDF.createOrReplaceTempView(\"tip_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Checkin Data"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val checkinDF \u003d spark.read.parquet(\"bdad_proj/checkin_data\")\ncheckinDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "checkinDF.createOrReplaceTempView(\"checkin_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "User Data"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val userDF \u003d spark.read.parquet(\"bdad_proj/user_data\")\nuserDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userDF.createOrReplaceTempView(\"user_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Reviews Data"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val revDF \u003d spark.read.parquet(\"bdad_proj/review_data\")\nrevDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "revDF.createOrReplaceTempView(\"rev_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Yelp Main Categories"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mainCatPath \u003d \"bdad_proj/yelp_main_categories\"\nval mainCatDF \u003d Seq(\n(\"Active Life\"),\n(\"Arts \u0026 Entertainment\"),\n(\"Automotive\"),\n(\"Beauty \u0026 Spas\"),\n(\"Education\"),\n(\"Event Planning \u0026 Services\"),\n(\"Financial Services\"),\n(\"Food\"),\n(\"Health \u0026 Medical\"),\n(\"Home Services\"),\n(\"Hotels \u0026 Travel\"),\n(\"Local Flavor\"),\n(\"Local Services\"),\n(\"Mass Media\"),\n(\"Nightlife\"),\n(\"Pets\"),\n(\"Professional Services\"),\n(\"Public Services \u0026 Government\"),\n(\"Real Estate\"),\n(\"Religious Organizations\"),\n(\"Restaurants\"),\n(\"Shopping\")).toDF(\"main_cat\")\nmainCatDF.show\nmainCatDF.write.mode(\"overwrite\").parquet(mainCatPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "mainCatDF.createOrReplaceTempView(\"main_cat_view\")"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Main Categories\nval bizMainCats \u003d spark.sql(\"select biz_cat_view.* from biz_cat_view, main_cat_view where biz_cat_view.category \u003d main_cat_view.main_cat\")\nbizMainCats.createOrReplaceTempView(\"biz_main_cats_view\")"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cuisineTypePath \u003d \"bdad_proj/cuisine_type\"\nval cuisineTypeDF \u003d \nSeq((\"Afghan\"),\n    (\"African\"),\n    (\"American (New)\"),\n    (\"American (Traditional)\"),\n    (\"Arabian\"),\n    (\"Argentine\"),\n    (\"Armenian\"),\n    (\"Asian Fusion\"),\n    (\"Australian\"),\n    (\"Austrian\"),\n    (\"Bangladeshi\"),\n    (\"Barbeque\"),\n    (\"Basque\"),\n    (\"Belgian\"),\n    (\"Brasseries\"),\n    (\"Brazilian\"),\n    (\"Breakfast \u0026 Brunch\"),\n    (\"British\"),\n    (\"Buffets\"),\n    (\"Bulgarian\"),\n    (\"Burgers\"),\n    (\"Burmese\"),\n    (\"Cafes\"),\n    (\"Themed Cafes\"),\n    (\"Cafeteria\"),\n    (\"Cajun/Creole\"),\n    (\"Cambodian\"),\n    (\"Caribbean\"),\n    (\"Catalan\"),\n    (\"Cheesesteaks\"),\n    (\"Chicken Shop\"),\n    (\"Chicken Wings\"),\n    (\"Chinese\"),\n    (\"Comfort Food\"),\n    (\"Creperies\"),\n    (\"Cuban\"),\n    (\"Czech\"),\n    (\"Delis\"),\n    (\"Diners\"),\n    (\"Dinner Theater\"),\n    (\"Eritrean\"),\n    (\"Ethiopian\"),\n    (\"Fast Food\"),\n    (\"Filipino\"),\n    (\"Fish \u0026 Chips\"),\n    (\"Fondue\"),\n    (\"Food Court\"),\n    (\"Food Stands\"),\n    (\"French\"),\n    (\"Game Meat\"),\n    (\"Gastropubs\"),\n    (\"Georgian\"),\n    (\"German\"),\n    (\"Gluten-Free\"),\n    (\"Greek\"),\n    (\"Guamanian\"),\n    (\"Halal\"),\n    (\"Hawaiian\"),\n    (\"Himalayan/Nepalese\"),\n    (\"Honduran\"),\n    (\"Hong Kong Style Cafe\"),\n    (\"Hot Dogs\"),\n    (\"Hot Pot\"),\n    (\"Hungarian\"),\n    (\"Iberian\"),\n    (\"Indian\"),\n    (\"Indonesian\"),\n    (\"Irish\"),\n    (\"Italian\"),\n    (\"Japanese\"),\n    (\"Kebab\"),\n    (\"Korean\"),\n    (\"Kosher\"),\n    (\"Laotian\"),\n    (\"Latin American\"),\n    (\"Live/Raw Food\"),\n    (\"Malaysian\"),\n    (\"Mediterranean\"),\n    (\"Mexican\"),\n    (\"Middle Eastern\"),\n    (\"Modern European\"),\n    (\"Mongolian\"),\n    (\"Moroccan\"),\n    (\"New Mexican Cuisine\"),\n    (\"Nicaraguan\"),\n    (\"Noodles\"),\n    (\"Pakistani\"),\n    (\"Pan Asia\"),\n    (\"Persian/Iranian\"),\n    (\"Peruvian\"),\n    (\"Pizza\"),\n    (\"Polish\"),\n    (\"Polynesian\"),\n    (\"Pop-Up Restaurants\"),\n    (\"Portuguese\"),\n    (\"Poutineries\"),\n    (\"Russian\"),\n    (\"Salad\"),\n    (\"Sandwiches\"),\n    (\"Scandinavian\"),\n    (\"Scottish\"),\n    (\"Seafood\"),\n    (\"Singaporean\"),\n    (\"Slovakian\"),\n    (\"Somali\"),\n    (\"Soul Food\"),\n    (\"Soup\"),\n    (\"Southern\"),\n    (\"Spanish\"),\n    (\"Sri Lankan\"),\n    (\"Steakhouses\"),\n    (\"Supper Clubs\"),\n    (\"Sushi Bars\"),\n    (\"Syrian\"),\n    (\"Taiwanese\"),\n    (\"Tapas Bars\"),\n    (\"Tapas/Small Plates\"),\n    (\"Tex-Mex\"),\n    (\"Thai\"),\n    (\"Turkish\"),\n    (\"Ukrainian\"),\n    (\"Uzbek\"),\n    (\"Vegan\"),\n    (\"Vegetarian\"),\n    (\"Vietnamese\"),\n    (\"Waffles\"),\n    (\"Wraps\")).toDF(\"type\")\ncuisineTypeDF.show\ncuisineTypeDF.write.mode(\"overwrite\").parquet(cuisineTypePath)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Fortune 500 in the US"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"SELECT name, business_id FROM biz_view WHERE name LIKE \u0027Walmart\u0027\").show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Positive Words\nNegative Words"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val posWordsDF \u003d spark.read.text(\"bdad_proj/positive-words.txt\").toDF(\"word\")\nval negWordsDF \u003d spark.read.text(\"bdad_proj/negative-words.txt\").toDF(\"word\")"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "posWordsDF.createOrReplaceTempView(\"pos_word_view\")\nnegWordsDF.createOrReplaceTempView(\"neg_word_view\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Useful Words"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval posUselessWord \u003d Seq(\"liked\", \"top\", \"a+\",\"great\",\"amazing\",\"love\",\"best\",\"awesome\",\"excellent\",\"good\",\"favorite\",\"loved\",\"perfect\",\"gem\",\"perfectly\",\"wonderful\",\"happy\",\"enjoyed\",\"nice\",\"well\",\"super\",\"like\",\"better\",\"decent\",\"fine\",\"pretty\",\"enough\",\"excite\",\"impressed\",\"ready\",\"fantastic\",\"glad\",\"right\",\"fabulous\",\"fun\",\"work\",\"recommended\",\"incredible\",\"outstanding\",\"pleasant\").toDF(\"word\")\nval negUselessWord \u003d Seq(\"bad\",\"disappointed\",\"unfortunately\",\"disappointing\",\"horrible\",\"lacking\",\"terrible\",\"sorry\",\"worse\",\"waste\",\"problem\",\"mediocre\",\"awful\",\"wrong\", \"worst\",\"sad\", \"hate\",\"upset\",\"shame\",\"complain\",\"excuse\",\"sucks\",\"joke\",\"negative\",\"fault\").toDF(\"word\")\nposUselessWord.createOrReplaceTempView(\"pos_useless_view\")\nnegUselessWord.createOrReplaceTempView(\"neg_useless_view\")\nspark.sql(\"SELECT word FROM pos_word_view EXCEPT SELECT word FROM pos_useless_view\").createOrReplaceTempView(\"useful_pos_word_view\")\nspark.sql(\"SELECT word FROM neg_word_view EXCEPT SELECT word FROM neg_useless_view\").createOrReplaceTempView(\"useful_neg_word_view\")"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val resultDir \u003d \"bdad_proj/results\""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Analytics"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Distribution of consumption types in different state"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Top 10 main categories per state"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catSql \u003d \"\"\"\n             |SELECT state, main_cat, count(business_id) AS cats_count\n             |FROM biz_view, main_cat_view\n             |WHERE array_contains(biz_view.categories, main_cat)\n             |GROUP BY state, main_cat\n             |ORDER BY cats_count DESC\n             \"\"\"\nspark.sql(catSql).createOrReplaceTempView(\"cat_rev_cnt_view\")\nval catByStateSql \u003d \"\"\"\n                    |SELECT state, main_cat, cats_count, rank() over(partition by state order by cats_count desc) as rank\n                    |FROM cat_rev_cnt_view\n                    \"\"\"\nval catsCntsPerStateDF \u003d spark.sql(catByStateSql).where($\"rank\" \u003c\u003d 10)\ncatsCntsPerStateDF.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Save all categories counts"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catPerStateCSVPath \u003d f\"$resultDir/cats_cnts_per_state\"\nrankDF.write.mode(\"overwrite\").csv(catPerStateCSVPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rankDF.createOrReplaceTempView(\"ranking\")\nval top10Sql \u003d \"select state, category, count, rank from ranking where rank \u003c\u003d 10\" \nval top10DF \u003d spark.sql(top10Sql)\ntop10DF.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Save result"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val top10CatPerStateCSVPath \u003d \"bdad_proj/results/top10_cats_per_state\"\ntop10DF.write.mode(\"overwrite\").csv(top10CatPerStateCSVPath)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Avg stars in terms of month"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val avgStarPerMonthFD \u003d revDF.select($\"date\", $\"stars\").groupBy(month($\"date\").as(\"m\")).avg(\"stars\").sort($\"m\")\navgStarPerMonthFD.show"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val avgStarPerMonthCSVPath \u003d f\"$resultDir/avg_stars_per_month\"\navgStarPerMonthFD.write.mode(\"overwrite\").csv(avgStarPerMonthCSVPath)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Most Popular Categories"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "revDF.select($\"business_id\", $\"stars\").createOrReplaceTempView(\"biz_stars_view\")\nmainCatDF.createOrReplaceTempView(\"main_cat_view\")"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val bizStarCatSql \u003d \"\"\"\n                    |SELECT\n                    |biz_cat_view.business_id, biz_stars_view.stars, main_cat_view.main_cat\n                    |FROM biz_cat_view, biz_stars_view, main_cat_view\n                    |WHERE main_cat_view.main_cat \u003d biz_cat_view.category\n                    |AND biz_cat_view.business_id \u003d biz_stars_view.business_id\n                    \"\"\"\nvar catRevCnt \u003d spark.sql(bizStarCatSql).groupBy($\"main_cat\").count.sort($\"count\".desc)\ncatRevCnt \u003d bizRevCnt.cache()\ncatRevCnt.show(false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Save Result"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "catRevCnt.write.mode(\"overwrite\").csv(f\"$resultDir/top_cat_rev_cnt\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Most visited restaurants\nOrder By `Merchant Review Count / Total Review Count in that State`"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "bizDF.createOrReplaceTempView(\"biz_view\")\nval revCntByStateSql \u003d \"\"\"\n                       |SELECT sum(review_count) as rev_cnt, state\n                       |FROM biz_view\n                       |WHERE array_contains(categories, \u0027Restaurants\u0027)\n                       |GROUP BY state\n                       \"\"\"\nval revCntByState \u003d spark.sql(revCntByStateSql)\nrevCntByState.createOrReplaceTempView(\"rev_cnt_by_state\")\n\nval restaurantsSql \u003d \"\"\"\n           |SELECT name, business_id, address, city, biz_view.state, review_count, review_count/rev_cnt_by_state.rev_cnt as rev_ratio\n           |FROM biz_view, rev_cnt_by_state\n           |WHERE biz_view.state\u003drev_cnt_by_state.state\n           |AND rev_cnt_by_state.rev_cnt \u003e 100\n           |ORDER BY rev_ratio DESC\n           |LIMIT 10\n           \"\"\"\nval restaurantsDF \u003d spark.sql(restaurantsSql)\nrestaurantsDF.show\nrestaurantsDF.write.mode(\"overwrite\").csv(f\"$resultDir/most_visited_restaurants\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Order By Absolute Review Count"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val restaurantsAbsSql \u003d \"\"\"\n           |SELECT name, business_id, address, city, state, review_count\n           |FROM biz_view\n           |WHERE array_contains(categories, \u0027Restaurants\u0027)\n           |ORDER BY review_count DESC\n           |LIMIT 10\n           \"\"\"\nval restaurantsAbsDF \u003d spark.sql(restaurantsAbsSql)\nrestaurantsAbsDF.show\nrestaurantsAbsDF.write.mode(\"overwrite\").csv(f\"$resultDir/most_visited_restaurants_abs\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Top 10 Cuisine Type\n"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "cuisineTypeDF.createOrReplaceTempView(\"cuisine_type_view\")\nval explodedBizFD \u003d spark.sql(\"SELECT *, explode(categories) as category FROM biz_view\")\nexplodedBizFD.createOrReplaceTempView(\"exploded_biz_view\")\nval top10CuisineTypeSql \u003d \"\"\"\n                          |SELECT type, sum(review_count) as rev_cnt\n                          |FROM exploded_biz_view, cuisine_type_view\n                          |WHERE category\u003dtype\n                          |GROUP BY type\n                          |ORDER BY rev_cnt DESC\n                          |LIMIT 10\n                          \"\"\"\nval top10CuisineTypeDF \u003d spark.sql(top10CuisineTypeSql)\ntop10CuisineTypeDF.write.mode(\"overwrite\").csv(f\"$resultDir/top10_cuisine_type\")"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "top10CuisineTypeDF.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Big Company Rate Distribution in Yelp Dataset\n1. Walmart\n2. Target\n3. AT\u0026T\n4. McDonald\u0027s\n5. Costco Wholesale"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val names \u003d Array(\"Walmart\", \"Target\", \"AT\u0026T\", \"McDonald\u0027s\", \"Costco Wholesale\")\ndef analytics6(name: String) \u003d {\n    val sql \u003d f\"select state, avg(stars) from biz_view where name\u003d\u0027$name\u0027 group by state\"\n    val df \u003d spark.sql(sql)\n    df.show\n}\n\nanalytics6(\"AT\u0026T\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Top 10 Cities with the Most Business Parties in Yelp Dataset"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "spark.sql(\"SELECT city, count(business_id) AS biz_cnt FROM biz_view GROUP BY city ORDER BY biz_cnt DESC LIMIT 10\")\n        .write.mode(\"overwrite\").csv(f\"$resultDir/top10_cities_the_most_merchants\")   "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Business with most Five Star Reviews from Users"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val sql \u003d \"\"\"\n          |SELECT biz_view.business_id, name, count(rev_view.review_id) AS five_cnt\n          |FROM biz_view, rev_view\n          |WHERE biz_view.business_id\u003drev_view.business_id\n          |AND rev_view.stars \u003d 5.0\n          |GROUP BY biz_view.business_id, name\n          |ORDER BY five_cnt DESC\n          |LIMIT 10\n          \"\"\"\nval top10FiveStarBus \u003d spark.sql(sql)\ntop10FiveStarBus.write.mode(\"overwrite\").csv(f\"$resultDir/top10_five_star_bus\")"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "top10FiveStarBus.show(false)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Geographical distribution of businesses"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val geoBizDistDF \u003d spark.sql(\"select business_id, stars, state, city, longitude, latitude from biz_view\")\ngeoBizDistDF.write.mode(\"overwrite\").csv(f\"$resultDir/geo_biz_dist\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. Top 10 cities and states with most reviews"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val top10RevState \u003d spark.sql(\n    \"\"\"\n    |SELECT state, rev_cnt\n    |FROM (SELECT COUNT(rev_view.review_id) as rev_cnt, state FROM rev_view, biz_view WHERE rev_view.business_id \u003d biz_view.business_id GROUP BY state) t1\n    |ORDER BY rev_cnt DESC\n    |LIMIT 10\n    \"\"\"\n)\ntop10RevState.write.mode(\"overwrite\").csv(f\"$resultDir/top10_rev_state\")"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val top10RevCity \u003d spark.sql(\n    \"\"\"\n    |SELECT city, rev_cnt\n    |FROM (SELECT COUNT(rev_view.review_id) as rev_cnt, city FROM rev_view, biz_view WHERE rev_view.business_id \u003d biz_view.business_id GROUP BY city) t1\n    |ORDER BY rev_cnt DESC\n    |LIMIT 10\n    \"\"\"\n)\ntop10RevCity.write.mode(\"overwrite\").csv(f\"$resultDir/top10_rev_city\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 11. Checkins variation across time in different categories\n1. Restaurants \n2. Shopping \n3. Nightlife \n4. Arts \u0026 Entertainment\n5. Food"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val sql1 \u003d \"\"\"\n          |SELECT business_id, hour(ts) as hour, weekday(ts) as weekday\n          |FROM checkin_view\n          \"\"\"\nspark.sql(sql1).createOrReplaceTempView(\"checkin_weeekday_view\")\n\ndef analytics11(cat: String) \u003d {\n    val output \u003d f\"$resultDir/checkin_time_dist/${cat.filterNot(_.isWhitespace).toLowerCase()}_weekdays_checkins_distribution\"\n    val weekday2str \u003d (weekday: Int) \u003d\u003e weekday match {\n      case 0 \u003d\u003e \"Sun\"\n      case 1 \u003d\u003e \"Mon\"\n      case 2 \u003d\u003e \"Tue\"\n      case 3 \u003d\u003e \"Wed\"\n      case 4 \u003d\u003e \"Thu\"\n      case 5 \u003d\u003e \"Fri\"\n      case 6 \u003d\u003e \"Sat\"\n    }\n    val sql2 \u003d f\"\"\"\n          |SELECT hour, weekday, weekday2str(weekday) as weekdayStr, count(weekday) as cnt, rank() over (partition by weekday order by hour)\n          |FROM checkin_weeekday_view, biz_view\n          |WHERE biz_view.business_id\u003dcheckin_weeekday_view.business_id AND array_contains(biz_view.categories, \"$cat\")\n          |GROUP BY weekday, hour\n          \"\"\"\n    spark.udf.register(\"weekday2str\", weekday2str)\n    spark.sql(sql2).na.drop.write.mode(\"overwrite\").csv(output)\n}\n\nval cats \u003d Array(\"Restaurants\", \"Shopping\", \"Nightlife\", \"Arts \u0026 Entertainment\", \"Food\")\nfor (cat \u003c- cats) {\n    analytics11(cat)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def analytics11_1(cat: String) \u003d {\n    val output \u003d f\"$resultDir/checkin_time_dist/${cat.filterNot(_.isWhitespace).toLowerCase()}_checkins_distribution\"\n    val sql \u003d f\"\"\"\n          |SELECT hour, count(hour) as cnt\n          |FROM checkin_weeekday_view, biz_view\n          |WHERE biz_view.business_id\u003dcheckin_weeekday_view.business_id AND array_contains(biz_view.categories, \"${cat}\")\n          |GROUP BY hour\n          \"\"\"\n    print(sql)\n    spark.sql(sql).na.drop.write.mode(\"overwrite\").csv(output)\n}\nval cats \u003d Array(\"Restaurants\", \"Shopping\", \"Nightlife\", \"Arts \u0026 Entertainment\", \"Food\")\nfor (cat \u003c- cats) {\n    analytics11_1(cat)\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 12. Reasons for positive and negative reviews in different categories\n1. Restaurants \n2. Shopping \n3. Nightlife \n4. Arts \u0026 Entertainment\n5. Food"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def analyticsFor12n13(resultDir: String, cat: String, desc: String) \u003d {\n    val posOutputPath \u003d f\"${resultDir}/rev_pos_word_freq/${desc}_rev_pos_word_freq\"\n    val negOutputPath \u003d f\"${resultDir}/rev_neg_word_freq/${desc}_rev_neg_word_freq\"\n\n    val catRevSql \u003d f\"\"\"\n                 |SELECT explode(words) as word, rev_view.stars\n                 |FROM rev_view, biz_view\n                 |WHERE rev_view.business_id\u003dbiz_view.business_id\n                 |AND array_contains(biz_view.categories, \u0027$cat\u0027)\n                 \"\"\"\n    val catRevDF \u003d spark.sql(catRevSql)\n    catRevDF.show\n    catRevDF.createOrReplaceTempView(\"cat_rev_view\")\n    \n    // classify reviews based on stars\n    val revPos \u003d catRevDF.where($\"stars\" \u003e\u003d 4.0)\n    val revNeu \u003d catRevDF.where($\"stars\" \u003e\u003d 3.0 \u0026\u0026 $\"stars\" \u003c 4.0)\n    val revNeg \u003d catRevDF.where($\"stars\" \u003c 3.0)\n    \n    revPos.createOrReplaceTempView(\"rev_pos_view\")\n    revNeu.createOrReplaceTempView(\"rev_neu_view\")\n    revNeg.createOrReplaceTempView(\"rev_neg_view\")\n    \n    // positive \n    val posWordFreqSql \u003d \"\"\"\n                     |SELECT rev_pos_view.word, count(rev_pos_view.word) as freq\n                     |FROM rev_pos_view, useful_pos_word_view\n                     |WHERE useful_pos_word_view.word\u003drev_pos_view.word\n                     |GROUP BY rev_pos_view.word\n                     |ORDER BY freq DESC\n                     \"\"\"\n    val revPosWordFreq \u003d spark.sql(posWordFreqSql)\n    revPosWordFreq.show(50)\n    revPosWordFreq.limit(50).write.mode(\"overwrite\").csv(posOutputPath)\n    \n    // negative\n    val negWordFreqSql \u003d \"\"\"\n                     |SELECT rev_neg_view.word, count(rev_neg_view.word) as freq\n                     |FROM rev_neg_view, useful_neg_word_view\n                     |WHERE useful_neg_word_view.word\u003drev_neg_view.word\n                     |GROUP BY rev_neg_view.word\n                     |ORDER BY freq DESC\n                     \"\"\"\n    val revNegWordFreq \u003d spark.sql(negWordFreqSql)\n    revNegWordFreq.show(50)\n    revNegWordFreq.limit(50).write.mode(\"overwrite\").csv(negOutputPath)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cuisines \u003d Array((\"Restaurants\", \"restaurants\"), (\"Shopping\", \"shopping\"), (\"Nightlife\", \"nightlife\"), (\"Arts \u0026 Entertainment\", \"ane\"), (\"Food\", \"food\"))\nfor (item \u003c- cuisines) {\n    analyticsFor12n13(resultDir, item._1, item._2)\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 13. Reasons for positive and negative reviews in different cuisine type\n1. Pizza \n2. Burgers \n3. Seafood\n4. Chinese\n5. Indian\n\n### Steps\n1. classify reviews based on stars\n2. split into words\n3. word frequency ranking\n4. find top 10 reasons for each type\n\n\u003ePositive Words\n\u003ehttps://gist.github.com/mkulakowski2/4289437\n\u003eNegative Words\n\u003ehttps://gist.github.com/mkulakowski2/4289441"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cuisines \u003d Array((\"Pizza\", \"pizza\"), (\"Italian\", \"italian\"), (\"Seafood\", \"seafood\"), (\"Mexican\", \"mexican\"), (\"Burgers\", \"burgers\"),(\"Chinese\", \"chinese\"), (\"Indian\", \"indian\"))\nfor (item \u003c- cuisines) {\n    analyticsFor12n13(resultDir, item._1, item._2)\n}\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14. Relation between number of fans and review count"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userDF.stat.corr(\"review_count\", \"fans\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Type are positively correlated"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 15. Predict how many stars a certain user would give\n\n### Steps\n1. see how many reviews a person has given\n2. using linear regression to produce the prediction model"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval userStarsSql \u003d \"\"\"\n                   |SELECT user_view.user_id, stars, category, fans, review_count, user_view.useful, user_view.funny, user_view.cool, average_stars\n                   |FROM user_view, rev_view, biz_cat_view \n                   |WHERE user_view.user_id\u003drev_view.user_id \n                   |AND biz_cat_view.business_id\u003drev_view.business_id\n                   \"\"\"\nval userStarsDF \u003d spark.sql(userStarsSql)\nuserStarsDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val Array(trainDF, testDF) \u003d userStarsDF.randomSplit(Array(.8, .2), seed\u003d23)\ntrainDF.write.mode(\"overwrite\").parquet(\"bdad_proj/user_star_ml/user_star_train\")\ntestDF.write.mode(\"overwrite\").parquet(\"bdad_proj/user_star_ml/user_star_test\")"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport scala.collection.mutable.ArrayBuffer\nimport org.apache.spark.ml.feature.VectorAssembler\n\nval categoricalCols \u003d trainDF.dtypes.filter(_._2 \u003d\u003d \"StringType\").map(_._1)\nvar indexOutputCols \u003d ArrayBuffer[String]()\nvar oheOutputCols \u003d ArrayBuffer[String]()\nval stringIndexer \u003d categoricalCols.map(colName \u003d\u003e {\n    indexOutputCols +\u003d (colName+\"I\")\n    new StringIndexer()\n        .setInputCol(colName)\n        .setOutputCol(colName+\"I\")\n        .setHandleInvalid(\"skip\")\n})\n  \nval oheEncoder \u003d categoricalCols.map(colName \u003d\u003e {\n    indexOutputCols +\u003d (colName+\"O\")\n    new OneHotEncoder()\n        .setInputCol(colName)\n        .setOutputCol(colName+\"O\")\n})\nval numericCols \u003d trainDF.dtypes.filter{ case (field, dataType) \u003d\u003e\n  dataType \u003d\u003d \"DoubleType\" || dataType \u003d\u003d \"LongType\"}.map(_._1)\nval assemblerInputs \u003d (oheOutputCols ++ numericCols).toArray\nval vecAssembler \u003d new VectorAssembler()\n                    .setInputCols(assemblerInputs)\n                    .setOutputCol(\"features\")\nval vecTrainDF \u003d vecAssembler.transform(trainDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "vecTrainDF.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Linear Regression"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.regression.LinearRegression\nval lr \u003d new LinearRegression()\n    .setFeaturesCol(\"features\")\n    .setLabelCol(\"stars\")\nval userStarCategoryModel \u003d lr.fit(vecTrainDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "userStarCategoryModel.save(f\"$resultDir/model/userStarCategoryModel\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Using Pipeline"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.Pipeline\nval pipeline \u003d new Pipeline().setStages(Array(vecAssembler, lr))\nval pipelineModel \u003d pipeline.fit(trainDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "pipelineModel.save(f\"$resultDir/model/userStarCategoryPipelineModel\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Predict stars rating by users with test dataset"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predDF \u003d pipelineModel.transform(testDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "predDF.show"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 16. Average length of words in each category\n\nRestaurants\nShopping\nNightlife\nArts \u0026 Entertainment\nFood\n\n\n1. Pizza \n2. Burgers \n3. Seafood\n4. Chinese\n5. Indian"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def analyticsFor16(resultDir: String, cat: String) \u003d {\n    val posOutputPath \u003d f\"${resultDir}/rev_pos_words_avg_len/${cat.filterNot(_.isWhitespace).toLowerCase()}_rev_pos_words_len\"\n    val negOutputPath \u003d f\"${resultDir}/rev_neg_words_avg_len/${cat.filterNot(_.isWhitespace).toLowerCase()}_rev_neg_words_len\"\n\n    println(posOutputPath)\n    println(negOutputPath)\n    \n    val catRevSql \u003d f\"\"\"\n                 |SELECT length(text) as review_len, rev_view.stars\n                 |FROM rev_view, biz_view\n                 |WHERE rev_view.business_id\u003dbiz_view.business_id\n                 |AND array_contains(biz_view.categories, \u0027$cat\u0027)\n                 \"\"\"\n    val catRevDF \u003d spark.sql(catRevSql)\n    catRevDF.show\n    catRevDF.createOrReplaceTempView(\"cat_rev_wl_view\")\n    \n    // classify reviews based on stars\n    val revPos \u003d catRevDF.where($\"stars\" \u003e\u003d 4.0)\n    val revNeu \u003d catRevDF.where($\"stars\" \u003e\u003d 3.0 \u0026\u0026 $\"stars\" \u003c 4.0)\n    val revNeg \u003d catRevDF.where($\"stars\" \u003c 3.0)\n    \n    revPos.createOrReplaceTempView(\"rev_pos_wl_view\")\n    revNeu.createOrReplaceTempView(\"rev_neu_wl_view\")\n    revNeg.createOrReplaceTempView(\"rev_neg_wl_view\")\n    \n    val posWlSql \u003d \"\"\"\n                   |SELECT avg(review_len)\n                   |FROM rev_pos_wl_view\n                   \"\"\"\n    spark.sql(posWlSql).write.mode(\"overwrite\").csv(posOutputPath)\n    \n    val negWlSql \u003d \"\"\"\n                   |SELECT avg(review_len)\n                   |FROM rev_neg_wl_view\n                   \"\"\"\n    spark.sql(negWlSql).write.mode(\"overwrite\").csv(negOutputPath)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cats \u003d Array[String](\"Restaurants\", \"Shopping\", \"Nightlife\", \"Arts \u0026 Entertainment\", \"Food\")\nfor (cat \u003c- cats) {\n    analyticsFor16(resultDir, cat)\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val cats \u003d Array[String](\"Pizza\",\"Burgers\",\"Seafood\",\"Chinese\",\"Indian\")\nfor (cat \u003c- cats) {\n    analyticsFor16(resultDir, cat)\n}"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 17. Distribution of positive and negative reviews in each category"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val posRev \u003d spark.sql(\"select * from rev_view where stars \u003e\u003d 4.0\")\nposRev.createOrReplaceTempView(\"pos_rev_view\")\n\nval sql \u003d \"\"\"\n          |SELECT t1.category, pos_cnt/cnt*100 as percentage\n          |FROM\n          |(SELECT category, COUNT(pos_rev_view.review_id) as pos_cnt\n          |FROM pos_rev_view, biz_main_cats_view \n          |WHERE biz_main_cats_view.business_id\u003dpos_rev_view.business_id\n          |GROUP BY biz_main_cats_view.category) t1,\n          |(SELECT category, COUNT(rev_view.review_id) as cnt\n          |FROM rev_view, biz_main_cats_view \n          |WHERE biz_main_cats_view.business_id\u003drev_view.business_id \n          |GROUP BY biz_main_cats_view.category) t2\n          |WHERE t1.category\u003dt2.category\n          |GROUP BY t1.category, pos_cnt, cnt\n          \"\"\"\nval posRevPerDF \u003d spark.sql(sql)\nposRevPerDF.write.mode(\"overwrite\").csv(f\"$resultDir/ana_17/pos_rev_percentage\")"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val sql \u003d \"\"\"\n          |SELECT category, avg(stars) as avg_stars\n          |FROM rev_view, biz_main_cats_view\n          |WHERE biz_main_cats_view.business_id\u003drev_view.business_id\n          |GROUP BY biz_main_cats_view.category\n          \"\"\"\nval avgRevPerCatDF \u003d spark.sql(sql)\navgRevPerCatDF.write.mode(\"overwrite\").csv(f\"$resultDir/ana_17/avg_rev_percentage_cat\")"
    }
  ]
}