{
 "metadata": {
  "name": "YelpRecommendSys",
  "kernelspec": {
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "import org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.ml.recommendation.ALS"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val rating_review = spark.read.format(\"parquet\").load(\"yelp_preprocess/yelp_review_with_ub_index\")\n// rating_review.show()"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val Array(training, test) = rating_review.randomSplit(Array(0.8, 0.2))"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val als = new ALS()\n        .setCheckpointInterval(5)\n        .setRank(15)\n        .setMaxIter(20)\n        .setRegParam(0.5)\n        .setUserCol(\"user_index\")\n        .setItemCol(\"business_index\")\n        .setRatingCol(\"stars\")\n\nval model = als.fit(training)"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val evaluator = new RegressionEvaluator()\n        .setMetricName(\"r2\")\n        .setLabelCol(\"stars\")\n        .setPredictionCol(\"prediction\")"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "model.setColdStartStrategy(\"drop\")\nval pred = model.transform(test)"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val r2 = evaluator.evaluate(pred)\nprintln(s\"R2 = $r2\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val userRecs = model.recommendForAllUsers(5)"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "userRecs.show(false)"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val user_rec_items = userRecs\n        .withColumn(\"item1_id\", $\"recommendations\".getItem(0).getItem(\"business_index\"))\n        .withColumn(\"item2_id\", $\"recommendations\".getItem(1).getItem(\"business_index\"))\n        .withColumn(\"item3_id\", $\"recommendations\".getItem(2).getItem(\"business_index\"))\n        .withColumn(\"item4_id\", $\"recommendations\".getItem(3).getItem(\"business_index\"))\n        .withColumn(\"item5_id\", $\"recommendations\".getItem(4).getItem(\"business_index\"))\n        .drop(\"recommendations\")"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "user_rec_items.show(false)"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val yelp_business = spark.read.format(\"json\").load(\"yelp_origin/yelp_academic_dataset_business.json\").select(\"business_id\", \"name\", \"categories\")\nyelp_business.show(false)"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val yelp_user = spark.read.format(\"json\").load(\"yelp_origin/yelp_academic_dataset_user.json\")"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val yelp_user_v2 = yelp_user.select(\"user_id\", \"name\")\nyelp_user_v2.show"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "val df = spark.read.format(\"parquet\").load(\"yelp\")\nval ratings = df.select(\"user_id\", \"business_id\", \"stars\", \"timestamp\")\n\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types.{StructField,StructType,IntegerType, LongType}\nimport org.apache.spark.sql.Row\n\ndef generate_index(df: DataFrame, col: String, new_col_name: String):DataFrame = {\n    val df_item = df.select(col).distinct()\n    val new_schema = StructType(df_item.schema.fields ++ Array(StructField(new_col_name, LongType, nullable = false)))\n    val df_rdd = df_item.rdd.zipWithIndex()\n    spark.createDataFrame(df_rdd.map{case (row, index) => Row.fromSeq(row.toSeq ++ Array(index))}, new_schema)    \n}\n\nval ratings_user = ratings.select(\"user_id\").distinct()\nval ratings_user_with_index = generate_index(ratings_user, \"user_id\", \"user_index\")\n\nval ratings_item = ratings.select(\"business_id\").distinct()\nval ratings_item_with_index = generate_index(ratings_item, \"business_id\", \"business_index\")"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": "//ratings_user_with_index.filter('user_index === 463).show(false)\n//ratings_user_with_index.filter('user_index === 471).show(false)\nratings_user_with_index.filter('user_index === 833).show(false)"
  }
 ]
}